{"@context":{"@language":"en","@vocab":"https://schema.org/","citeAs":"cr:citeAs","column":"cr:column","conformsTo":"dct:conformsTo","cr":"http://mlcommons.org/croissant/","data":{"@id":"cr:data","@type":"@json"},"dataBiases":"cr:dataBiases","dataCollection":"cr:dataCollection","dataType":{"@id":"cr:dataType","@type":"@vocab"},"dct":"http://purl.org/dc/terms/","extract":"cr:extract","field":"cr:field","fileProperty":"cr:fileProperty","fileObject":"cr:fileObject","fileSet":"cr:fileSet","format":"cr:format","includes":"cr:includes","isEnumeration":"cr:isEnumeration","jsonPath":"cr:jsonPath","key":"cr:key","md5":"cr:md5","parentField":"cr:parentField","path":"cr:path","personalSensitiveInformation":"cr:personalSensitiveInformation","recordSet":"cr:recordSet","references":"cr:references","regex":"cr:regex","repeated":"cr:repeated","replace":"cr:replace","sc":"https://schema.org/","separator":"cr:separator","source":"cr:source","subField":"cr:subField","transform":"cr:transform","wd":"https://www.wikidata.org/wiki/"},"alternateName":"YOLO Object Detection Playground | 1000\u002B Videos","conformsTo":"http://mlcommons.org/croissant/1.0","license":{"@type":"sc:CreativeWork","name":"Other (specified in description)"},"distribution":[{"contentUrl":"https://www.kaggle.com/api/v1/datasets/download/sshikamaru/car-object-detection?datasetVersionNumber=2","contentSize":"112.063 MB","md5":"0Ud4fABKhKhhvbfoiJejWw==","encodingFormat":"application/zip","@id":"archive.zip","@type":"cr:FileObject","name":"archive.zip","description":"Archive containing all the contents of the Car Object Detection dataset"},{"includes":"*.jpg","containedIn":{"@id":"archive.zip"},"encodingFormat":"image/jpeg","@id":"image-jpeg_fileset","@type":"cr:FileSet","name":"image/jpeg files","description":"image/jpeg files contained in archive.zip"},{"contentUrl":"data/sample_submission.csv","containedIn":{"@id":"archive.zip"},"encodingFormat":"text/csv","@id":"sample_submission.csv_fileobject","@type":"cr:FileObject","name":"sample_submission.csv","description":"Sample Submission\n\n"},{"contentUrl":"data/train_solution_bounding_boxes (1).csv","containedIn":{"@id":"archive.zip"},"encodingFormat":"text/csv","@id":"train_solution_bounding_boxes\u002B(1).csv_fileobject","@type":"cr:FileObject","name":"train_solution_bounding_boxes (1).csv","description":"Bounding coordinates for each object in the training data"}],"recordSet":[{"field":[{"dataType":["sc:Text"],"source":{"fileObject":{"@id":"sample_submission.csv_fileobject"},"extract":{"column":"image"}},"@id":"sample_submission.csv/image","@type":"cr:Field","name":"image"},{"dataType":["sc:Text"],"source":{"fileObject":{"@id":"sample_submission.csv_fileobject"},"extract":{"column":"bounds"}},"@id":"sample_submission.csv/bounds","@type":"cr:Field","name":"bounds"}],"@id":"sample_submission.csv","@type":"cr:RecordSet","name":"sample_submission.csv","description":"Sample Submission\n\n"},{"field":[{"dataType":["sc:Text"],"source":{"fileObject":{"@id":"train_solution_bounding_boxes\u002B(1).csv_fileobject"},"extract":{"column":"image"}},"@id":"train_solution_bounding_boxes\u002B(1).csv/image","@type":"cr:Field","name":"image"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"train_solution_bounding_boxes\u002B(1).csv_fileobject"},"extract":{"column":"xmin"}},"@id":"train_solution_bounding_boxes\u002B(1).csv/xmin","@type":"cr:Field","name":"xmin"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"train_solution_bounding_boxes\u002B(1).csv_fileobject"},"extract":{"column":"ymin"}},"@id":"train_solution_bounding_boxes\u002B(1).csv/ymin","@type":"cr:Field","name":"ymin"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"train_solution_bounding_boxes\u002B(1).csv_fileobject"},"extract":{"column":"xmax"}},"@id":"train_solution_bounding_boxes\u002B(1).csv/xmax","@type":"cr:Field","name":"xmax"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"train_solution_bounding_boxes\u002B(1).csv_fileobject"},"extract":{"column":"ymax"}},"@id":"train_solution_bounding_boxes\u002B(1).csv/ymax","@type":"cr:Field","name":"ymax"}],"@id":"train_solution_bounding_boxes\u002B(1).csv","@type":"cr:RecordSet","name":"train_solution_bounding_boxes (1).csv","description":"Bounding coordinates for each object in the training data"}],"version":2,"keywords":["technique \u003E computer vision","subject \u003E science and technology \u003E computer science \u003E artificial intelligence","subject \u003E science and technology \u003E transportation \u003E automobiles and vehicles"],"isAccessibleForFree":true,"includedInDataCatalog":{"@type":"sc:DataCatalog","name":"Kaggle","url":"https://www.kaggle.com"},"creator":{"@type":"sc:Person","name":"Edward Zhang","url":"/sshikamaru","image":"https://storage.googleapis.com/kaggle-avatars/thumbnails/2504634-kg.png"},"publisher":{"@type":"sc:Organization","name":"Kaggle","url":"https://www.kaggle.com/organizations/kaggle","image":"https://storage.googleapis.com/kaggle-organizations/4/thumbnail.png"},"thumbnailUrl":"https://storage.googleapis.com/kaggle-datasets-images/843852/1440019/f7e0ed99f527fdcdf7442d56f945ae93/dataset-card.png?t=2020-08-24-19-59-18","dateModified":"2022-06-26T17:37:34.22","datePublished":"2020-08-24T20:06:03.5236348","@type":"sc:Dataset","name":"Car Object Detection","url":"https://www.kaggle.com/datasets/sshikamaru/car-object-detection/versions/2","description":"### Context\n\nYOLO (\u0022you only look once\u0022) is a popular algoritm because it achieves high accuracy while also being able to run in real-time, almost clocking 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. This algorithm \u0022only looks once\u0022 at the image in the sense that it requires only one forward propagation pass through the network to make predictions. After non-max suppression, it then outputs recognized objects together with the bounding boxes.\n\n### Content\nThe dataset contains media of cars in all views, and your job is to create an algorithm to detect them!\n\n\n### Acknowledgements\n\nI got this dataset from TJHSST from one of the competitions they hosted.\n\n"}